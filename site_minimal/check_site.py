#!/usr/bin/env python3
"""
ã‚µã‚¤ãƒˆå“è³ªãƒã‚§ãƒƒã‚¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒªãƒ³ã‚¯åˆ‡ã‚Œã€HTMLæ§‹æ–‡ã€ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ç­‰ã‚’ç·åˆçš„ã«æ¤œè¨¼
"""

import os
import re
from pathlib import Path
from urllib.parse import urljoin, urlparse
import json

class SiteQualityChecker:
    def __init__(self):
        self.base_dir = Path(__file__).parent
        self.issues = []
        self.warnings = []
        self.successes = []
        
    def log_issue(self, level, category, message, file_path=None):
        """å•é¡Œã‚’ãƒ­ã‚°ã«è¨˜éŒ²"""
        entry = {
            "level": level,
            "category": category, 
            "message": message,
            "file": str(file_path) if file_path else None
        }
        
        if level == "error":
            self.issues.append(entry)
        elif level == "warning":
            self.warnings.append(entry)
        else:
            self.successes.append(entry)
    
    def find_all_html_files(self):
        """ã™ã¹ã¦ã®HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¦‹ã¤ã‘ã‚‹"""
        html_files = []
        for html_file in self.base_dir.rglob("*.html"):
            if "templates" not in str(html_file):  # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¯é™¤å¤–
                html_files.append(html_file)
        return html_files
    
    def extract_links_from_html(self, file_path):
        """HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒªãƒ³ã‚¯ã‚’æŠ½å‡º"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # hrefãƒªãƒ³ã‚¯ã‚’æŠ½å‡º
            href_pattern = r'href=["\']([^"\']+)["\']'
            links = re.findall(href_pattern, content)
            
            # srcãƒªãƒ³ã‚¯ã‚‚æŠ½å‡ºï¼ˆç”»åƒã€JSã€CSSï¼‰
            src_pattern = r'src=["\']([^"\']+)["\']'
            src_links = re.findall(src_pattern, content)
            
            return links, src_links
            
        except Exception as e:
            self.log_issue("error", "file_access", f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", file_path)
            return [], []
    
    def check_link_exists(self, link, base_file_path):
        """ãƒªãƒ³ã‚¯å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        # å¤–éƒ¨ãƒªãƒ³ã‚¯ã¯ã‚¹ã‚­ãƒƒãƒ—
        if link.startswith(('http://', 'https://', 'mailto:', 'tel:')):
            return True
        
        # ã‚¢ãƒ³ã‚«ãƒ¼ãƒªãƒ³ã‚¯ã¯ã‚¹ã‚­ãƒƒãƒ—
        if link.startswith('#'):
            return True
        
        # ç›¸å¯¾ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
        if link.startswith('/'):
            # ãƒ«ãƒ¼ãƒˆç›¸å¯¾ãƒ‘ã‚¹
            target_path = self.base_dir / link.lstrip('/')
        else:
            # ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®ç›¸å¯¾ãƒ‘ã‚¹
            target_path = base_file_path.parent / link
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å ´åˆã¯index.htmlã‚’ç¢ºèª
        if target_path.is_dir():
            target_path = target_path / "index.html"
        
        # æ‹¡å¼µå­ãŒãªã„å ´åˆã‚‚index.htmlã‚’ç¢ºèª
        if not target_path.suffix and not target_path.exists():
            target_path = target_path / "index.html"
        
        return target_path.exists()
    
    def check_broken_links(self):
        """ãƒªãƒ³ã‚¯åˆ‡ã‚Œã‚’ãƒã‚§ãƒƒã‚¯"""
        print("ğŸ”— ãƒªãƒ³ã‚¯åˆ‡ã‚Œãƒã‚§ãƒƒã‚¯ä¸­...")
        
        html_files = self.find_all_html_files()
        total_links = 0
        broken_links = 0
        
        for html_file in html_files:
            links, src_links = self.extract_links_from_html(html_file)
            all_links = links + src_links
            
            for link in all_links:
                total_links += 1
                
                if not self.check_link_exists(link, html_file):
                    broken_links += 1
                    self.log_issue("error", "broken_link", 
                                 f"ãƒªãƒ³ã‚¯åˆ‡ã‚Œ: {link}", html_file)
        
        if broken_links == 0:
            self.log_issue("success", "links", f"âœ… ã™ã¹ã¦ã®ãƒªãƒ³ã‚¯ãŒæ­£å¸¸ ({total_links}å€‹)")
        else:
            self.log_issue("error", "links", f"âŒ {broken_links}/{total_links}å€‹ã®ãƒªãƒ³ã‚¯ãŒåˆ‡ã‚Œã¦ã„ã¾ã™")
    
    def check_html_structure(self):
        """HTMLæ§‹é€ ã‚’ãƒã‚§ãƒƒã‚¯"""
        print("ğŸ“„ HTMLæ§‹é€ ãƒã‚§ãƒƒã‚¯ä¸­...")
        
        html_files = self.find_all_html_files()
        
        for html_file in html_files:
            try:
                with open(html_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # åŸºæœ¬çš„ãªHTMLæ§‹é€ ãƒã‚§ãƒƒã‚¯
                checks = [
                    (r'<!DOCTYPE html>', "DOCTYPEå®£è¨€"),
                    (r'<html[^>]*lang=["\']ja["\']', "langå±æ€§"),
                    (r'<meta[^>]*charset=["\']UTF-8["\']', "æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°"),
                    (r'<meta[^>]*viewport[^>]*>', "viewportè¨­å®š"),
                    (r'<title>', "titleã‚¿ã‚°"),
                    (r'<meta[^>]*description[^>]*>', "description meta"),
                ]
                
                for pattern, description in checks:
                    if not re.search(pattern, content, re.IGNORECASE):
                        self.log_issue("warning", "html_structure", 
                                     f"{description}ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", html_file)
                
                # è¦‹å‡ºã—ã®éšå±¤ãƒã‚§ãƒƒã‚¯
                headings = re.findall(r'<(h[1-6])', content, re.IGNORECASE)
                if headings:
                    # h1ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    if 'h1' not in [h.lower() for h in headings]:
                        self.log_issue("warning", "accessibility", 
                                     "h1ã‚¿ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", html_file)
                
            except Exception as e:
                self.log_issue("error", "file_access", 
                             f"HTMLãƒ•ã‚¡ã‚¤ãƒ«è§£æã‚¨ãƒ©ãƒ¼: {e}", html_file)
    
    def check_accessibility(self):
        """ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ã‚’ãƒã‚§ãƒƒã‚¯"""
        print("â™¿ ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ä¸­...")
        
        html_files = self.find_all_html_files()
        
        for html_file in html_files:
            try:
                with open(html_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ç”»åƒã®altå±æ€§ãƒã‚§ãƒƒã‚¯
                img_tags = re.findall(r'<img[^>]*>', content, re.IGNORECASE)
                for img_tag in img_tags:
                    if 'alt=' not in img_tag:
                        self.log_issue("warning", "accessibility",
                                     f"altå±æ€§ãŒãªã„ç”»åƒ: {img_tag[:50]}...", html_file)
                
                # ãƒªãƒ³ã‚¯ã®aria-labelãƒã‚§ãƒƒã‚¯ï¼ˆã‚¢ã‚¤ã‚³ãƒ³ã®ã¿ã®å ´åˆï¼‰
                icon_links = re.findall(r'<a[^>]*>[\s]*<span[^>]*>[ğŸ”ï¸ğŸ’ğŸ‘ŸğŸ§¥ğŸ“šğŸ›¡ï¸ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ğŸ—¼ğŸ¯â™¨ï¸]</span>[\s]*</a>', content)
                for link in icon_links:
                    if 'aria-label=' not in link:
                        self.log_issue("warning", "accessibility",
                                     "ã‚¢ã‚¤ã‚³ãƒ³ãƒªãƒ³ã‚¯ã«aria-labelãŒã‚ã‚Šã¾ã›ã‚“", html_file)
                
                # ã‚¹ã‚­ãƒƒãƒ—ãƒªãƒ³ã‚¯ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
                if 'skip-link' not in content and 'main-content' in content:
                    self.log_issue("warning", "accessibility",
                                 "ã‚¹ã‚­ãƒƒãƒ—ãƒªãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", html_file)
                
            except Exception as e:
                self.log_issue("error", "file_access", 
                             f"ã‚¢ã‚¯ã‚»ã‚·ãƒ“ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}", html_file)
    
    def check_css_references(self):
        """CSSå‚ç…§ã‚’ãƒã‚§ãƒƒã‚¯"""
        print("ğŸ¨ CSSå‚ç…§ãƒã‚§ãƒƒã‚¯ä¸­...")
        
        html_files = self.find_all_html_files()
        
        for html_file in html_files:
            try:
                with open(html_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # CSSãƒ•ã‚¡ã‚¤ãƒ«ã®å‚ç…§ã‚’ãƒã‚§ãƒƒã‚¯
                css_links = re.findall(r'<link[^>]*href=["\']([^"\']*\.css)["\']', content)
                for css_link in css_links:
                    if not self.check_link_exists(css_link, html_file):
                        self.log_issue("error", "css", 
                                     f"CSSãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {css_link}", html_file)
                
            except Exception as e:
                self.log_issue("error", "file_access", 
                             f"CSSå‚ç…§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}", html_file)
    
    def check_js_references(self):
        """JavaScriptå‚ç…§ã‚’ãƒã‚§ãƒƒã‚¯"""
        print("âš¡ JavaScriptå‚ç…§ãƒã‚§ãƒƒã‚¯ä¸­...")
        
        html_files = self.find_all_html_files()
        
        for html_file in html_files:
            try:
                with open(html_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # JSãƒ•ã‚¡ã‚¤ãƒ«ã®å‚ç…§ã‚’ãƒã‚§ãƒƒã‚¯
                js_links = re.findall(r'<script[^>]*src=["\']([^"\']*\.js)["\']', content)
                for js_link in js_links:
                    if not self.check_link_exists(js_link, html_file):
                        self.log_issue("error", "javascript", 
                                     f"JavaScriptãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {js_link}", html_file)
                
            except Exception as e:
                self.log_issue("error", "file_access", 
                             f"JavaScriptå‚ç…§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}", html_file)
    
    def check_image_references(self):
        """ç”»åƒå‚ç…§ã‚’ãƒã‚§ãƒƒã‚¯"""
        print("ğŸ–¼ï¸ ç”»åƒå‚ç…§ãƒã‚§ãƒƒã‚¯ä¸­...")
        
        html_files = self.find_all_html_files()
        
        for html_file in html_files:
            try:
                with open(html_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å‚ç…§ã‚’ãƒã‚§ãƒƒã‚¯
                img_srcs = re.findall(r'<img[^>]*src=["\']([^"\']*)["\']', content)
                for img_src in img_srcs:
                    if not self.check_link_exists(img_src, html_file):
                        self.log_issue("error", "images", 
                                     f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {img_src}", html_file)
                
            except Exception as e:
                self.log_issue("error", "file_access", 
                             f"ç”»åƒå‚ç…§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}", html_file)
    
    def check_responsive_design(self):
        """ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯"""
        print("ğŸ“± ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³ãƒã‚§ãƒƒã‚¯ä¸­...")
        
        css_file = self.base_dir / "css" / "minimal_design.css"
        
        if css_file.exists():
            try:
                with open(css_file, 'r', encoding='utf-8') as f:
                    css_content = f.read()
                
                # ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¯ã‚¨ãƒªã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
                media_queries = re.findall(r'@media[^{]+\{', css_content)
                if len(media_queries) < 3:
                    self.log_issue("warning", "responsive", 
                                 f"ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¯ã‚¨ãƒªãŒå°‘ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ ({len(media_queries)}å€‹)")
                else:
                    self.log_issue("success", "responsive", 
                                 f"âœ… é©åˆ‡ãªãƒ¡ãƒ‡ã‚£ã‚¢ã‚¯ã‚¨ãƒªãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ ({len(media_queries)}å€‹)")
                
                # viewportã®è¨­å®šç¢ºèª
                html_files = self.find_all_html_files()
                for html_file in html_files:
                    with open(html_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    if 'viewport' not in content:
                        self.log_issue("error", "responsive", 
                                     "viewport meta tagãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“", html_file)
                        
            except Exception as e:
                self.log_issue("error", "file_access", 
                             f"ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            self.log_issue("error", "css", "CSSãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    def check_seo_basics(self):
        """åŸºæœ¬çš„ãªSEOã‚’ãƒã‚§ãƒƒã‚¯"""
        print("ğŸ” SEOåŸºæœ¬ãƒã‚§ãƒƒã‚¯ä¸­...")
        
        html_files = self.find_all_html_files()
        
        for html_file in html_files:
            try:
                with open(html_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # titleã‚¿ã‚°ã®é•·ã•ãƒã‚§ãƒƒã‚¯
                title_match = re.search(r'<title>([^<]+)</title>', content, re.IGNORECASE)
                if title_match:
                    title_length = len(title_match.group(1))
                    if title_length > 60:
                        self.log_issue("warning", "seo", 
                                     f"titleãŒé•·ã™ãã¾ã™ ({title_length}æ–‡å­—)", html_file)
                    elif title_length < 10:
                        self.log_issue("warning", "seo", 
                                     f"titleãŒçŸ­ã™ãã¾ã™ ({title_length}æ–‡å­—)", html_file)
                
                # descriptionã®é•·ã•ãƒã‚§ãƒƒã‚¯
                desc_match = re.search(r'<meta[^>]*name=["\']description["\'][^>]*content=["\']([^"\']+)["\']', content, re.IGNORECASE)
                if desc_match:
                    desc_length = len(desc_match.group(1))
                    if desc_length > 160:
                        self.log_issue("warning", "seo", 
                                     f"descriptionãŒé•·ã™ãã¾ã™ ({desc_length}æ–‡å­—)", html_file)
                    elif desc_length < 50:
                        self.log_issue("warning", "seo", 
                                     f"descriptionãŒçŸ­ã™ãã¾ã™ ({desc_length}æ–‡å­—)", html_file)
                
                # æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚§ãƒƒã‚¯
                if 'application/ld+json' not in content:
                    self.log_issue("warning", "seo", 
                                 "æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“", html_file)
                
            except Exception as e:
                self.log_issue("error", "file_access", 
                             f"SEOãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}", html_file)
    
    def check_file_structure(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã‚’ãƒã‚§ãƒƒã‚¯"""
        print("ğŸ“‚ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ãƒã‚§ãƒƒã‚¯ä¸­...")
        
        # å¿…é ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        required_dirs = ['css', 'js', 'images', 'mountains', 'equipment', 'beginner']
        for dir_name in required_dirs:
            dir_path = self.base_dir / dir_name
            if not dir_path.exists():
                self.log_issue("error", "structure", f"å¿…é ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {dir_name}")
            else:
                self.log_issue("success", "structure", f"âœ… {dir_name}ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª")
        
        # å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ãƒã‚§ãƒƒã‚¯
        required_files = [
            'index.html',
            'css/minimal_design.css',
            'js/minimal.js'
        ]
        for file_path in required_files:
            full_path = self.base_dir / file_path
            if not full_path.exists():
                self.log_issue("error", "structure", f"å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
            else:
                self.log_issue("success", "structure", f"âœ… {file_path}ç¢ºèª")
    
    def generate_site_map(self):
        """ã‚µã‚¤ãƒˆãƒãƒƒãƒ—ã‚’ç”Ÿæˆ"""
        print("ğŸ—ºï¸ ã‚µã‚¤ãƒˆãƒãƒƒãƒ—ç”Ÿæˆä¸­...")
        
        html_files = self.find_all_html_files()
        site_map = {}
        
        for html_file in html_files:
            relative_path = html_file.relative_to(self.base_dir)
            
            # URLãƒ‘ã‚¹ã«å¤‰æ›
            if relative_path.name == 'index.html':
                if relative_path.parent == Path('.'):
                    url_path = '/'
                else:
                    url_path = f"/{relative_path.parent}/"
            else:
                url_path = f"/{relative_path}"
            
            # ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º
            try:
                with open(html_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                title_match = re.search(r'<title>([^<]+)</title>', content, re.IGNORECASE)
                title = title_match.group(1) if title_match else str(relative_path)
                
                site_map[url_path] = {
                    "title": title,
                    "file": str(relative_path)
                }
                
            except Exception as e:
                site_map[url_path] = {
                    "title": "ã‚¨ãƒ©ãƒ¼",
                    "file": str(relative_path),
                    "error": str(e)
                }
        
        return site_map
    
    def run_all_checks(self):
        """ã™ã¹ã¦ã®ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ"""
        print("ğŸ” ã‚µã‚¤ãƒˆå“è³ªãƒã‚§ãƒƒã‚¯é–‹å§‹")
        print("=" * 50)
        
        # å„ç¨®ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
        self.check_file_structure()
        self.check_broken_links()
        self.check_html_structure()
        self.check_accessibility()
        self.check_css_references()
        self.check_js_references()
        self.check_image_references()
        self.check_responsive_design()
        self.check_seo_basics()
        
        # ã‚µã‚¤ãƒˆãƒãƒƒãƒ—ç”Ÿæˆ
        site_map = self.generate_site_map()
        
        # çµæœãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
        self.print_results(site_map)
        
        return len(self.issues) == 0
    
    def print_results(self, site_map):
        """çµæœã‚’è¡¨ç¤º"""
        print("\n" + "=" * 50)
        print("ğŸ“Š ã‚µã‚¤ãƒˆå“è³ªãƒã‚§ãƒƒã‚¯çµæœ")
        print("=" * 50)
        
        # æˆåŠŸé …ç›®
        if self.successes:
            print(f"\nâœ… æˆåŠŸé …ç›® ({len(self.successes)}å€‹):")
            for success in self.successes:
                print(f"  {success['message']}")
        
        # è­¦å‘Šé …ç›®
        if self.warnings:
            print(f"\nâš ï¸ è­¦å‘Šé …ç›® ({len(self.warnings)}å€‹):")
            for warning in self.warnings:
                file_info = f" ({warning['file']})" if warning['file'] else ""
                print(f"  [{warning['category']}] {warning['message']}{file_info}")
        
        # ã‚¨ãƒ©ãƒ¼é …ç›®
        if self.issues:
            print(f"\nâŒ ã‚¨ãƒ©ãƒ¼é …ç›® ({len(self.issues)}å€‹):")
            for issue in self.issues:
                file_info = f" ({issue['file']})" if issue['file'] else ""
                print(f"  [{issue['category']}] {issue['message']}{file_info}")
        
        # ã‚µã‚¤ãƒˆãƒãƒƒãƒ—
        print(f"\nğŸ—ºï¸ ã‚µã‚¤ãƒˆãƒãƒƒãƒ— ({len(site_map)}ãƒšãƒ¼ã‚¸):")
        for url, info in sorted(site_map.items()):
            if 'error' in info:
                print(f"  {url} - âŒ {info['error']}")
            else:
                print(f"  {url} - {info['title']}")
        
        # ç·åˆè©•ä¾¡
        print("\n" + "=" * 50)
        if len(self.issues) == 0:
            if len(self.warnings) == 0:
                print("ğŸ‰ å®Œç’§ï¼ã™ã¹ã¦ã®ãƒã‚§ãƒƒã‚¯ã«åˆæ ¼ã—ã¾ã—ãŸ")
                grade = "A+"
            else:
                print("âœ… è‰¯å¥½ï¼é‡å¤§ãªå•é¡Œã¯ã‚ã‚Šã¾ã›ã‚“")
                grade = "A"
        elif len(self.issues) <= 3:
            print("âš ï¸ æ³¨æ„ï¼è»½å¾®ãªå•é¡ŒãŒã‚ã‚Šã¾ã™")
            grade = "B"
        elif len(self.issues) <= 10:
            print("ğŸ”§ ä¿®æ­£å¿…è¦ï¼è¤‡æ•°ã®å•é¡ŒãŒã‚ã‚Šã¾ã™")
            grade = "C"
        else:
            print("ğŸš¨ è¦ä¿®æ­£ï¼å¤šæ•°ã®å•é¡ŒãŒã‚ã‚Šã¾ã™")
            grade = "D"
        
        print(f"ç·åˆè©•ä¾¡: {grade}")
        print(f"ã‚¨ãƒ©ãƒ¼: {len(self.issues)}å€‹ | è­¦å‘Š: {len(self.warnings)}å€‹ | æˆåŠŸ: {len(self.successes)}å€‹")

def main():
    checker = SiteQualityChecker()
    is_perfect = checker.run_all_checks()
    
    if is_perfect:
        print("\nğŸš€ ã‚µã‚¤ãƒˆã¯å…¬é–‹æº–å‚™å®Œäº†ã§ã™ï¼")
    else:
        print("\nğŸ”§ å•é¡Œã‚’ä¿®æ­£ã—ã¦ã‹ã‚‰å…¬é–‹ã—ã¦ãã ã•ã„")
    
    return 0 if is_perfect else 1

if __name__ == "__main__":
    exit(main())