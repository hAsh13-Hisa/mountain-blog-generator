#!/usr/bin/env python3
"""
ã‚µã‚¤ãƒˆå“è³ªå•é¡Œã®ä¿®æ­£ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ¤œå‡ºã•ã‚ŒãŸå•é¡Œã‚’è‡ªå‹•ä¿®æ­£
"""

import re
from pathlib import Path

class SiteFixer:
    def __init__(self):
        self.base_dir = Path(__file__).parent
        
    def fix_missing_mountain_images(self):
        """ä¸è¶³ã—ã¦ã„ã‚‹å±±ç”»åƒã‚’æ—¢å­˜ç”»åƒã§ä»£æ›¿"""
        print("ğŸ–¼ï¸ ä¸è¶³ã—ã¦ã„ã‚‹å±±ç”»åƒã‚’ä¿®æ­£ä¸­...")
        
        # æ—¢å­˜ã®å±±ç”»åƒ
        existing_images = {
            "takao": "mountain_takao.svg",
            "tsukuba": "mountain_tsukuba.svg", 
            "sanuki": "mountain_sanuki.svg"
        }
        
        # ä»£æ›¿ãƒãƒƒãƒ”ãƒ³ã‚°
        fallback_mapping = {
            "å††": "takao",
            "å‡½é¤¨": "takao",
            "å²©æœ¨": "tsukuba",
            "é‡‘è¯": "tsukuba",
            "å¡©è¦‹": "sanuki",
            "é‹¸": "sanuki",
            "å¤§å¹³": "takao",
            "æµ…é–“": "tsukuba",
            "æ¸‹æ²¢ä¸˜é™µ": "takao"
        }
        
        # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
        html_files = list(self.base_dir.rglob("*.html"))
        for html_file in html_files:
            try:
                with open(html_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ç”»åƒãƒ‘ã‚¹ã‚’ä¿®æ­£
                for mountain_key, fallback_key in fallback_mapping.items():
                    fallback_image = existing_images[fallback_key]
                    
                    # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¿®æ­£
                    patterns = [
                        f'src="([^"]*)/mountain_{mountain_key}[^"]*\\.svg"',
                        f"src='([^']*)/mountain_{mountain_key}[^']*\\.svg'"
                    ]
                    
                    for pattern in patterns:
                        content = re.sub(
                            pattern,
                            lambda m: f'src="{m.group(1)}/{fallback_image}"',
                            content
                        )
                
                # æ›´æ–°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                with open(html_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                    
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {html_file} - {e}")
        
        print("âœ… å±±ç”»åƒã®ä¿®æ­£å®Œäº†")
    
    def fix_skip_links(self):
        """ã‚¹ã‚­ãƒƒãƒ—ãƒªãƒ³ã‚¯ã‚’è¿½åŠ """
        print("â™¿ ã‚¹ã‚­ãƒƒãƒ—ãƒªãƒ³ã‚¯ã‚’è¿½åŠ ä¸­...")
        
        html_files = list(self.base_dir.rglob("*.html"))
        for html_file in html_files:
            # index.htmlä»¥å¤–ã‚’å‡¦ç†ï¼ˆindex.htmlã«ã¯æ—¢ã«ã‚ã‚‹ï¼‰
            if html_file.name == "index.html" and html_file.parent == self.base_dir:
                continue
                
            try:
                with open(html_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ã‚¹ã‚­ãƒƒãƒ—ãƒªãƒ³ã‚¯ãŒæ—¢ã«ã‚ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                if 'skip-link' in content:
                    continue
                
                # <body>ã‚¿ã‚°ã®ç›´å¾Œã«ã‚¹ã‚­ãƒƒãƒ—ãƒªãƒ³ã‚¯ã‚’æŒ¿å…¥
                skip_link = '''    <!-- Skip Link -->
    <a href="#main-content" class="sr-only">ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¸ã‚¹ã‚­ãƒƒãƒ—</a>

'''
                
                content = re.sub(
                    r'(<body[^>]*>)',
                    r'\1\n' + skip_link,
                    content
                )
                
                with open(html_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                    
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {html_file} - {e}")
        
        print("âœ… ã‚¹ã‚­ãƒƒãƒ—ãƒªãƒ³ã‚¯ã®è¿½åŠ å®Œäº†")
    
    def fix_seo_descriptions(self):
        """SEOç”¨ã®descriptionã‚’æ”¹å–„"""
        print("ğŸ” SEO descriptionã‚’æ”¹å–„ä¸­...")
        
        # ã‚ˆã‚Šè‰¯ã„description
        improved_descriptions = {
            "ã“ã®ã‚µã‚¤ãƒˆã«ã¤ã„ã¦": "ä½å±±æ—…è¡Œã¯åˆå¿ƒè€…ãƒ»ãƒ•ã‚¡ãƒŸãƒªãƒ¼å‘ã‘ã®ä½å±±ãƒã‚¤ã‚­ãƒ³ã‚°æƒ…å ±ã‚µã‚¤ãƒˆã§ã™ã€‚å®‰å…¨ã§æ¥½ã—ã„å±±æ­©ãã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚",
            "ãŠå•ã„åˆã‚ã›": "ä½å±±æ—…è¡Œã‚µã‚¤ãƒˆã¸ã®ãŠå•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ã€‚å±±ã®æƒ…å ±ã‚„è£…å‚™ã«é–¢ã™ã‚‹ã”è³ªå•ã‚’ãŠæ°—è»½ã«ãŠå¯„ã›ãã ã•ã„ã€‚",
            "åœ°åŸŸåˆ¥ã‚¬ã‚¤ãƒ‰": "å…¨å›½47éƒ½é“åºœçœŒã®ä½å±±ã‚’åœ°åŸŸåˆ¥ã«ã”ç´¹ä»‹ã€‚ãŠä½ã¾ã„ã®åœ°åŸŸã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹è‰¯å¥½ãªå±±ã‚’è¦‹ã¤ã‘ã¾ã—ã‚‡ã†ã€‚",
            "åˆ©ç”¨è¦ç´„": "ä½å±±æ—…è¡Œã‚µã‚¤ãƒˆã®åˆ©ç”¨è¦ç´„ã€‚ã‚µã‚¤ãƒˆã”åˆ©ç”¨æ™‚ã®ãƒ«ãƒ¼ãƒ«ã‚„æ³¨æ„äº‹é …ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ã„ã¾ã™ã€‚",
            "ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼": "ä½å±±æ—…è¡Œã‚µã‚¤ãƒˆã®ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã€‚å€‹äººæƒ…å ±ã®å–ã‚Šæ‰±ã„ã‚„Cookieã®ä½¿ç”¨ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã€‚"
        }
        
        html_files = list(self.base_dir.rglob("*.html"))
        for html_file in html_files:
            try:
                with open(html_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # titleã‹ã‚‰ãƒšãƒ¼ã‚¸ç¨®åˆ¥ã‚’åˆ¤å®š
                title_match = re.search(r'<title>([^<-]+)', content)
                if title_match:
                    page_title = title_match.group(1).strip()
                    
                    for key, description in improved_descriptions.items():
                        if key in page_title:
                            # æ—¢å­˜ã®descriptionã‚’ç½®æ›
                            content = re.sub(
                                r'<meta name="description" content="[^"]*"',
                                f'<meta name="description" content="{description}"',
                                content,
                                flags=re.IGNORECASE
                            )
                            break
                
                with open(html_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                    
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {html_file} - {e}")
        
        print("âœ… SEO descriptionã®æ”¹å–„å®Œäº†")
    
    def add_image_fallbacks(self):
        """ç”»åƒã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œã‚’è¿½åŠ """
        print("ğŸ–¼ï¸ ç”»åƒãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œã‚’è¿½åŠ ä¸­...")
        
        html_files = list(self.base_dir.rglob("*.html"))
        for html_file in html_files:
            try:
                with open(html_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # onerrorãƒãƒ³ãƒ‰ãƒ©ã‚’è¿½åŠ ï¼ˆæ—¢ã«ãªã„å ´åˆï¼‰
                content = re.sub(
                    r'(<img[^>]*src="[^"]*mountain_[^"]*\.svg"[^>]*)(>)',
                    lambda m: m.group(1) + ' onerror="this.src=\'{}/images/hero_mountain_hiking.svg\'".format(window.location.origin)' + m.group(2) if 'onerror' not in m.group(1) else m.group(0),
                    content
                )
                
                with open(html_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                    
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {html_file} - {e}")
        
        print("âœ… ç”»åƒãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯¾å¿œå®Œäº†")
    
    def fix_all_issues(self):
        """ã™ã¹ã¦ã®å•é¡Œã‚’ä¿®æ­£"""
        print("ğŸ”§ ã‚µã‚¤ãƒˆå“è³ªå•é¡Œä¿®æ­£é–‹å§‹")
        print("=" * 50)
        
        self.fix_missing_mountain_images()
        self.fix_skip_links()
        self.fix_seo_descriptions()
        self.add_image_fallbacks()
        
        print("=" * 50)
        print("ğŸ‰ ã™ã¹ã¦ã®ä¿®æ­£å®Œäº†ï¼")

def main():
    fixer = SiteFixer()
    fixer.fix_all_issues()
    
    print("\nğŸš€ ä¿®æ­£å¾Œã®ç¢ºèªæ–¹æ³•:")
    print("python3 check_site.py ã§å†ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

if __name__ == "__main__":
    main()