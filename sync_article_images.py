#!/usr/bin/env python3
"""
è¨˜äº‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿JSONã‚’åŸºã«ã€è¨˜äº‹ãƒšãƒ¼ã‚¸ã¨ä¸€è¦§ãƒšãƒ¼ã‚¸ã®ç”»åƒã‚’åŒæœŸ
"""
import json
from pathlib import Path
import re

class ArticleImageSynchronizer:
    def __init__(self):
        self.metadata_file = Path('data/article_metadata.json')
        self.static_dir = Path('static_site')
        
    def load_metadata(self):
        """è¨˜äº‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        with open(self.metadata_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def save_metadata(self, metadata):
        """è¨˜äº‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        with open(self.metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    def extract_article_images(self):
        """å„è¨˜äº‹ãƒšãƒ¼ã‚¸ã‹ã‚‰ç¾åœ¨ã®ç”»åƒURLã‚’æŠ½å‡º"""
        metadata = self.load_metadata()
        updated = False
        
        print("ğŸ“¸ è¨˜äº‹ãƒšãƒ¼ã‚¸ã‹ã‚‰ç”»åƒURLã‚’æŠ½å‡ºä¸­...")
        
        for article_id, article_data in metadata['articles'].items():
            article_path = self.static_dir / article_data['url'].strip('/') / 'index.html'
            
            if article_path.exists():
                content = article_path.read_text(encoding='utf-8')
                
                # featured-image ã‚¯ãƒ©ã‚¹ã®ç”»åƒã‚’æ¢ã™
                match = re.search(r'<img[^>]*src="([^"]*)"[^>]*class="featured-image"', content)
                if match:
                    current_image = match.group(1)
                    if current_image != article_data.get('featured_image'):
                        print(f"  ğŸ“· {article_data['title']}: ç”»åƒURLæ›´æ–°")
                        print(f"     æ—§: {article_data.get('featured_image', 'ãªã—')}")
                        print(f"     æ–°: {current_image}")
                        article_data['featured_image'] = current_image
                        updated = True
        
        if updated:
            self.save_metadata(metadata)
            print("âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
        else:
            print("âœ… å…¨ã¦ã®ç”»åƒURLã¯æœ€æ–°ã§ã™")
        
        return metadata
    
    def sync_list_page(self, metadata=None):
        """ä¸€è¦§ãƒšãƒ¼ã‚¸ã®ç”»åƒã‚’ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã¨åŒæœŸ"""
        if metadata is None:
            metadata = self.load_metadata()
        
        list_page = self.static_dir / 'mountains' / 'index.html'
        content = list_page.read_text(encoding='utf-8')
        updated_content = content
        
        print("\nğŸ”„ å±±ä¸€è¦§ãƒšãƒ¼ã‚¸ã®ç”»åƒã‚’åŒæœŸä¸­...")
        
        for article_id, article_data in metadata['articles'].items():
            # ç¾åœ¨ã®ç”»åƒURLã‚’æ¢ã—ã¦ç½®æ›
            pattern = rf'(<a href="{article_data["url"]}"[^>]*>)\s*<img[^>]*src="[^"]*"([^>]*alt="{re.escape(article_data["title"])}")'
            replacement = rf'\1\n                    <img src="{article_data["featured_image"]}"\2'
            
            new_content = re.sub(pattern, replacement, updated_content, flags=re.DOTALL)
            
            if new_content != updated_content:
                print(f"  âœ… {article_data['title']}: åŒæœŸå®Œäº†")
                updated_content = new_content
            else:
                # altå±æ€§ã«ï¼ˆï¼‰ãŒå«ã¾ã‚Œã‚‹å ´åˆã®å¯¾å¿œ
                alt_variations = [
                    article_data["title"],
                    article_data["title"].split("ï¼ˆ")[0],  # ï¼ˆï¼‰ã‚’é™¤å»
                    article_data.get("subtitle", "").split("ã€‘")[-1].strip()  # ã‚µãƒ–ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰å–å¾—
                ]
                
                for alt_text in alt_variations:
                    pattern = rf'(<a href="{article_data["url"]}"[^>]*>)\s*<img[^>]*src="[^"]*"([^>]*alt="{re.escape(alt_text)}")'
                    new_content = re.sub(pattern, replacement, updated_content, flags=re.DOTALL)
                    
                    if new_content != updated_content:
                        print(f"  âœ… {article_data['title']}: åŒæœŸå®Œäº† (alt: {alt_text})")
                        updated_content = new_content
                        break
                else:
                    print(f"  âš ï¸  {article_data['title']}: ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        if updated_content != content:
            list_page.write_text(updated_content, encoding='utf-8')
            print("\nâœ… å±±ä¸€è¦§ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°ã—ã¾ã—ãŸ")
        else:
            print("\nâœ… å±±ä¸€è¦§ãƒšãƒ¼ã‚¸ã¯æ—¢ã«æœ€æ–°ã§ã™")
    
    def verify_sync(self):
        """åŒæœŸçŠ¶æ…‹ã‚’ç¢ºèª"""
        metadata = self.load_metadata()
        list_page = self.static_dir / 'mountains' / 'index.html'
        list_content = list_page.read_text(encoding='utf-8')
        
        print("\nğŸ” ç”»åƒåŒæœŸçŠ¶æ…‹ã®ç¢ºèª:")
        all_synced = True
        
        for article_id, article_data in metadata['articles'].items():
            # è¨˜äº‹ãƒšãƒ¼ã‚¸ã®ç”»åƒ
            article_path = self.static_dir / article_data['url'].strip('/') / 'index.html'
            article_image = "ä¸æ˜"
            
            if article_path.exists():
                article_content = article_path.read_text(encoding='utf-8')
                match = re.search(r'<img[^>]*src="([^"]*)"[^>]*class="featured-image"', article_content)
                if match:
                    article_image = match.group(1)
            
            # ä¸€è¦§ãƒšãƒ¼ã‚¸ã®ç”»åƒ
            list_pattern = rf'href="{article_data["url"]}"[^>]*>.*?<img[^>]*src="([^"]*)"'
            list_match = re.search(list_pattern, list_content, re.DOTALL)
            list_image = list_match.group(1) if list_match else "ä¸æ˜"
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç”»åƒ
            metadata_image = article_data.get('featured_image', 'æœªè¨­å®š')
            
            if article_image == list_image == metadata_image:
                print(f"  âœ… {article_data['title']}: å®Œå…¨åŒæœŸ")
            else:
                print(f"  âŒ {article_data['title']}:")
                print(f"     è¨˜äº‹ãƒšãƒ¼ã‚¸: {article_image}")
                print(f"     ä¸€è¦§ãƒšãƒ¼ã‚¸: {list_image}")
                print(f"     ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {metadata_image}")
                all_synced = False
        
        return all_synced

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    syncer = ArticleImageSynchronizer()
    
    # 1. è¨˜äº‹ãƒšãƒ¼ã‚¸ã‹ã‚‰ç”»åƒURLã‚’æŠ½å‡ºã—ã¦ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
    metadata = syncer.extract_article_images()
    
    # 2. ä¸€è¦§ãƒšãƒ¼ã‚¸ã‚’åŒæœŸ
    syncer.sync_list_page(metadata)
    
    # 3. åŒæœŸçŠ¶æ…‹ã‚’ç¢ºèª
    if syncer.verify_sync():
        print("\nâœ… å…¨ã¦ã®ç”»åƒãŒå®Œå…¨ã«åŒæœŸã•ã‚Œã¦ã„ã¾ã™ï¼")
    else:
        print("\nâš ï¸  åŒæœŸã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()